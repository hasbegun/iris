# ML Service Environment Configuration

# Server
HOST=0.0.0.0
PORT=9001
ENVIRONMENT=development

# YOLO Model Paths
DETECTION_MODEL_PATH=models/yolo11n.pt
SEGMENTATION_MODEL_PATH=models/yolo11n-seg.pt
FACE_MODEL_PATH=models/yolo11n-face.pt

# Inference Configuration
# Use "cuda" for NVIDIA GPU, "mps" for Apple Silicon GPU, "cpu" for CPU
DEVICE=cpu
BATCH_SIZE=1
MAX_IMAGE_SIZE=1920

# Performance
NUM_WORKERS=4
MODEL_WARMUP=true

# Image Processing
MAX_FILE_SIZE_MB=10

# Model Download
AUTO_DOWNLOAD_MODELS=true
