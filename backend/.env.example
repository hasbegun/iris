# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
VISION_MODEL=llava:latest
CHAT_MODEL=gemma3:latest

# API Configuration
API_HOST=0.0.0.0
API_PORT=9000

# Context Management
MAX_CONTEXT_MESSAGES=10
CONTEXT_TTL_SECONDS=3600

# Video Processing
VIDEO_FRAME_INTERVAL=1.0
MAX_VIDEO_DURATION=300

# ML Service Configuration
ML_SERVICE_URL=http://localhost:9001
ML_SERVICE_TIMEOUT=30
ML_SERVICE_RETRY_ATTEMPTS=3

# Agent Configuration
AGENT_LLM_MODEL=gemma3:latest
AGENT_MAX_ITERATIONS=5
AGENT_VERBOSE=true
YOLO_DEFAULT_CONFIDENCE=0.5
